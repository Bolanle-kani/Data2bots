{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Real work.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOGMccdY5RnOIjVNUdCMd9l",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bolanle-kani/Data2bots/blob/master/Real_work.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xAMovdkQv_KA",
        "outputId": "8dd79ac6-df2c-434f-c35e-4d02f807e189"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KbE-ortTwK-A",
        "outputId": "7e693c8a-712e-4381-9f55-bbbde58cd172"
      },
      "source": [
        "! pip install rasterio\n",
        "! pip install radiant_mlhub\n",
        "! pip install eo-learn"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting rasterio\n",
            "  Downloading rasterio-1.2.6-cp37-cp37m-manylinux1_x86_64.whl (19.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.3 MB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from rasterio) (1.19.5)\n",
            "Collecting affine\n",
            "  Downloading affine-2.3.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting cligj>=0.5\n",
            "  Downloading cligj-0.7.2-py3-none-any.whl (7.1 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from rasterio) (57.2.0)\n",
            "Collecting snuggs>=1.4.1\n",
            "  Downloading snuggs-1.4.7-py3-none-any.whl (5.4 kB)\n",
            "Collecting click-plugins\n",
            "  Downloading click_plugins-1.1.1-py2.py3-none-any.whl (7.5 kB)\n",
            "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.7/dist-packages (from rasterio) (7.1.2)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from rasterio) (21.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from rasterio) (2021.5.30)\n",
            "Requirement already satisfied: pyparsing>=2.1.6 in /usr/local/lib/python3.7/dist-packages (from snuggs>=1.4.1->rasterio) (2.4.7)\n",
            "Installing collected packages: snuggs, cligj, click-plugins, affine, rasterio\n",
            "Successfully installed affine-2.3.0 click-plugins-1.1.1 cligj-0.7.2 rasterio-1.2.6 snuggs-1.4.7\n",
            "Collecting radiant_mlhub\n",
            "  Downloading radiant_mlhub-0.2.2-py3-none-any.whl (26 kB)\n",
            "Collecting pystac==0.5.4\n",
            "  Downloading pystac-0.5.4-py3-none-any.whl (133 kB)\n",
            "\u001b[K     |████████████████████████████████| 133 kB 7.5 MB/s \n",
            "\u001b[?25hCollecting requests~=2.25.1\n",
            "  Downloading requests-2.25.1-py2.py3-none-any.whl (61 kB)\n",
            "\u001b[K     |████████████████████████████████| 61 kB 7.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: click~=7.1.2 in /usr/local/lib/python3.7/dist-packages (from radiant_mlhub) (7.1.2)\n",
            "Collecting tqdm~=4.56.0\n",
            "  Downloading tqdm-4.56.2-py2.py3-none-any.whl (72 kB)\n",
            "\u001b[K     |████████████████████████████████| 72 kB 1.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.0 in /usr/local/lib/python3.7/dist-packages (from pystac==0.5.4->radiant_mlhub) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.0->pystac==0.5.4->radiant_mlhub) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests~=2.25.1->radiant_mlhub) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests~=2.25.1->radiant_mlhub) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests~=2.25.1->radiant_mlhub) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests~=2.25.1->radiant_mlhub) (1.24.3)\n",
            "Installing collected packages: tqdm, requests, pystac, radiant-mlhub\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.41.1\n",
            "    Uninstalling tqdm-4.41.1:\n",
            "      Successfully uninstalled tqdm-4.41.1\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.25.1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed pystac-0.5.4 radiant-mlhub-0.2.2 requests-2.25.1 tqdm-4.56.2\n",
            "Collecting eo-learn\n",
            "  Downloading eo_learn-0.9.2-py3-none-any.whl (6.8 kB)\n",
            "Collecting eo-learn-geometry>=0.9.2\n",
            "  Downloading eo_learn_geometry-0.9.2-py3-none-any.whl (17 kB)\n",
            "Collecting eo-learn-ml-tools>=0.9.0\n",
            "  Downloading eo_learn_ml_tools-0.9.0-py3-none-any.whl (18 kB)\n",
            "Collecting eo-learn-core>=0.9.2\n",
            "  Downloading eo_learn_core-0.9.2-py3-none-any.whl (47 kB)\n",
            "\u001b[K     |████████████████████████████████| 47 kB 3.0 MB/s \n",
            "\u001b[?25hCollecting eo-learn-mask>=0.9.0\n",
            "  Downloading eo_learn_mask-0.9.0-py3-none-any.whl (10.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.5 MB 7.1 MB/s \n",
            "\u001b[?25hCollecting eo-learn-io>=0.9.2\n",
            "  Downloading eo_learn_io-0.9.2-py3-none-any.whl (21 kB)\n",
            "Collecting eo-learn-coregistration>=0.9.0\n",
            "  Downloading eo_learn_coregistration-0.9.0-py3-none-any.whl (11 kB)\n",
            "Collecting eo-learn-visualization>=0.9.0\n",
            "  Downloading eo_learn_visualization-0.9.0-py3-none-any.whl (14 kB)\n",
            "Collecting eo-learn-features>=0.9.2\n",
            "  Downloading eo_learn_features-0.9.2-py3-none-any.whl (36 kB)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.7/dist-packages (from eo-learn-core>=0.9.2->eo-learn) (1.19.5)\n",
            "Collecting geopandas!=0.8.0,>=0.5.0\n",
            "  Downloading geopandas-0.9.0-py2.py3-none-any.whl (994 kB)\n",
            "\u001b[K     |████████████████████████████████| 994 kB 45.2 MB/s \n",
            "\u001b[?25hCollecting fs\n",
            "  Downloading fs-2.4.13-py2.py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 65.0 MB/s \n",
            "\u001b[?25hCollecting boto3\n",
            "  Downloading boto3-1.18.14-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 55.3 MB/s \n",
            "\u001b[?25hCollecting sentinelhub>=3.1.0\n",
            "  Downloading sentinelhub-3.3.2.tar.gz (196 kB)\n",
            "\u001b[K     |████████████████████████████████| 196 kB 66.4 MB/s \n",
            "\u001b[?25hCollecting fs-s3fs\n",
            "  Downloading fs_s3fs-1.1.1-py2.py3-none-any.whl (9.7 kB)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from eo-learn-core>=0.9.2->eo-learn) (2.8.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from eo-learn-core>=0.9.2->eo-learn) (4.56.2)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.7/dist-packages (from eo-learn-core>=0.9.2->eo-learn) (21.2.0)\n",
            "Collecting opencv-contrib-python-headless>=4.1\n",
            "  Downloading opencv_contrib_python_headless-4.5.3.56-cp37-cp37m-manylinux2014_x86_64.whl (43.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 43.3 MB 16 kB/s \n",
            "\u001b[?25hCollecting thunder-registration\n",
            "  Downloading thunder-registration-1.0.1.tar.gz (5.4 kB)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (from eo-learn-features>=0.9.2->eo-learn) (0.16.2)\n",
            "Requirement already satisfied: numba>=0.43.1 in /usr/local/lib/python3.7/dist-packages (from eo-learn-features>=0.9.2->eo-learn) (0.51.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from eo-learn-features>=0.9.2->eo-learn) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from eo-learn-features>=0.9.2->eo-learn) (0.22.2.post1)\n",
            "Requirement already satisfied: descartes in /usr/local/lib/python3.7/dist-packages (from eo-learn-geometry>=0.9.2->eo-learn) (1.1.0)\n",
            "Collecting rasterio<=1.1.8\n",
            "  Downloading rasterio-1.1.8-1-cp37-cp37m-manylinux1_x86_64.whl (18.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 18.3 MB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: shapely in /usr/local/lib/python3.7/dist-packages (from eo-learn-geometry>=0.9.2->eo-learn) (1.7.1)\n",
            "Collecting rtree\n",
            "  Downloading Rtree-0.9.7-cp37-cp37m-manylinux2010_x86_64.whl (994 kB)\n",
            "\u001b[K     |████████████████████████████████| 994 kB 57.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: lightgbm>=2.0.11 in /usr/local/lib/python3.7/dist-packages (from eo-learn-mask>=0.9.0->eo-learn) (2.2.3)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.7/dist-packages (from eo-learn-ml-tools>=0.9.0->eo-learn) (0.11.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from eo-learn-ml-tools>=0.9.0->eo-learn) (1.1.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from eo-learn-ml-tools>=0.9.0->eo-learn) (3.2.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from eo-learn-visualization>=0.9.0->eo-learn) (2.11.3)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from eo-learn-visualization>=0.9.0->eo-learn) (2.6.1)\n",
            "Requirement already satisfied: graphviz>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from eo-learn-visualization>=0.9.0->eo-learn) (0.10.1)\n",
            "Requirement already satisfied: pydot in /usr/local/lib/python3.7/dist-packages (from eo-learn-visualization>=0.9.0->eo-learn) (1.3.0)\n",
            "Collecting fiona>=1.8\n",
            "  Downloading Fiona-1.8.20-cp37-cp37m-manylinux1_x86_64.whl (15.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 15.4 MB 38 kB/s \n",
            "\u001b[?25hCollecting pyproj>=2.2.0\n",
            "  Downloading pyproj-3.1.0-cp37-cp37m-manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 60.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas!=0.8.0,>=0.5.0->eo-learn-core>=0.9.2->eo-learn) (2021.5.30)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas!=0.8.0,>=0.5.0->eo-learn-core>=0.9.2->eo-learn) (57.2.0)\n",
            "Collecting munch\n",
            "  Downloading munch-2.5.0-py2.py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: six>=1.7 in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas!=0.8.0,>=0.5.0->eo-learn-core>=0.9.2->eo-learn) (1.15.0)\n",
            "Requirement already satisfied: click-plugins>=1.0 in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas!=0.8.0,>=0.5.0->eo-learn-core>=0.9.2->eo-learn) (1.1.1)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas!=0.8.0,>=0.5.0->eo-learn-core>=0.9.2->eo-learn) (0.7.2)\n",
            "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas!=0.8.0,>=0.5.0->eo-learn-core>=0.9.2->eo-learn) (7.1.2)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.1->eo-learn-features>=0.9.2->eo-learn) (0.34.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->eo-learn-ml-tools>=0.9.0->eo-learn) (2018.9)\n",
            "Requirement already satisfied: affine in /usr/local/lib/python3.7/dist-packages (from rasterio<=1.1.8->eo-learn-geometry>=0.9.2->eo-learn) (2.3.0)\n",
            "Requirement already satisfied: snuggs>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from rasterio<=1.1.8->eo-learn-geometry>=0.9.2->eo-learn) (1.4.7)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->eo-learn-features>=0.9.2->eo-learn) (2.5.1)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->eo-learn-features>=0.9.2->eo-learn) (1.1.1)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->eo-learn-features>=0.9.2->eo-learn) (2.4.1)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->eo-learn-features>=0.9.2->eo-learn) (7.1.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->eo-learn-ml-tools>=0.9.0->eo-learn) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->eo-learn-ml-tools>=0.9.0->eo-learn) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->eo-learn-ml-tools>=0.9.0->eo-learn) (1.3.1)\n",
            "Requirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx>=2.0->scikit-image->eo-learn-features>=0.9.2->eo-learn) (4.4.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from sentinelhub>=3.1.0->eo-learn-core>=0.9.2->eo-learn) (0.36.2)\n",
            "Requirement already satisfied: requests>=2.5.0 in /usr/local/lib/python3.7/dist-packages (from sentinelhub>=3.1.0->eo-learn-core>=0.9.2->eo-learn) (2.25.1)\n",
            "Requirement already satisfied: tifffile in /usr/local/lib/python3.7/dist-packages (from sentinelhub>=3.1.0->eo-learn-core>=0.9.2->eo-learn) (2021.7.2)\n",
            "Collecting utm\n",
            "  Downloading utm-0.7.0.tar.gz (8.7 kB)\n",
            "Collecting botocore\n",
            "  Downloading botocore-1.21.14-py3-none-any.whl (7.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.8 MB 39.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: oauthlib in /usr/local/lib/python3.7/dist-packages (from sentinelhub>=3.1.0->eo-learn-core>=0.9.2->eo-learn) (3.1.1)\n",
            "Requirement already satisfied: requests_oauthlib in /usr/local/lib/python3.7/dist-packages (from sentinelhub>=3.1.0->eo-learn-core>=0.9.2->eo-learn) (1.3.0)\n",
            "Collecting aenum>=2.1.4\n",
            "  Downloading aenum-3.1.0-py3-none-any.whl (123 kB)\n",
            "\u001b[K     |████████████████████████████████| 123 kB 77.3 MB/s \n",
            "\u001b[?25hCollecting dataclasses-json\n",
            "  Downloading dataclasses_json-0.5.4-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.5.0->sentinelhub>=3.1.0->eo-learn-core>=0.9.2->eo-learn) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.5.0->sentinelhub>=3.1.0->eo-learn-core>=0.9.2->eo-learn) (1.24.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.5.0->sentinelhub>=3.1.0->eo-learn-core>=0.9.2->eo-learn) (3.0.4)\n",
            "Collecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
            "Collecting s3transfer<0.6.0,>=0.5.0\n",
            "  Downloading s3transfer-0.5.0-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 6.8 MB/s \n",
            "\u001b[?25hCollecting urllib3<1.27,>=1.21.1\n",
            "  Downloading urllib3-1.26.6-py2.py3-none-any.whl (138 kB)\n",
            "\u001b[K     |████████████████████████████████| 138 kB 56.9 MB/s \n",
            "\u001b[?25hCollecting marshmallow<4.0.0,>=3.3.0\n",
            "  Downloading marshmallow-3.13.0-py2.py3-none-any.whl (47 kB)\n",
            "\u001b[K     |████████████████████████████████| 47 kB 4.2 MB/s \n",
            "\u001b[?25hCollecting stringcase<2.0.0,==1.2.0\n",
            "  Downloading stringcase-1.2.0.tar.gz (3.0 kB)\n",
            "Collecting typing-inspect>=0.4.0\n",
            "  Downloading typing_inspect-0.7.1-py3-none-any.whl (8.4 kB)\n",
            "Collecting marshmallow-enum<2.0.0,>=1.5.1\n",
            "  Downloading marshmallow_enum-1.5.1-py2.py3-none-any.whl (4.2 kB)\n",
            "Collecting mypy-extensions>=0.3.0\n",
            "  Downloading mypy_extensions-0.4.3-py2.py3-none-any.whl (4.5 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from typing-inspect>=0.4.0->dataclasses-json->sentinelhub>=3.1.0->eo-learn-core>=0.9.2->eo-learn) (3.7.4.3)\n",
            "Requirement already satisfied: appdirs~=1.4.3 in /usr/local/lib/python3.7/dist-packages (from fs->eo-learn-core>=0.9.2->eo-learn) (1.4.4)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->eo-learn-visualization>=0.9.0->eo-learn) (2.0.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->eo-learn-features>=0.9.2->eo-learn) (1.0.1)\n",
            "Collecting thunder-python>=1.2.0\n",
            "  Downloading thunder-python-1.4.2.tar.gz (44 kB)\n",
            "\u001b[K     |████████████████████████████████| 44 kB 1.9 MB/s \n",
            "\u001b[?25hCollecting boto>=2.36.0\n",
            "  Downloading boto-2.49.0-py2.py3-none-any.whl (1.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 43.4 MB/s \n",
            "\u001b[?25hCollecting bolt-python>=0.7.0\n",
            "  Downloading bolt-python-0.7.1.tar.gz (25 kB)\n",
            "Building wheels for collected packages: sentinelhub, stringcase, thunder-registration, thunder-python, bolt-python, utm\n",
            "  Building wheel for sentinelhub (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentinelhub: filename=sentinelhub-3.3.2-py3-none-any.whl size=210768 sha256=56ac7121e1304646c1193d7caf4ab1bd305d369e503e96aad3db57fc423e8d38\n",
            "  Stored in directory: /root/.cache/pip/wheels/f9/f6/b3/86022511db328ed2e95f5aaa48fc8abab2b4b71b0a7922a9f5\n",
            "  Building wheel for stringcase (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for stringcase: filename=stringcase-1.2.0-py3-none-any.whl size=3586 sha256=1b36cc0d4299a249e2a6cbb7354d53773514058285eb46eb2d4f89b00003e347\n",
            "  Stored in directory: /root/.cache/pip/wheels/86/ab/a3/a8fa7e0a07e80f547e03468c03827f8257f7339327986faed1\n",
            "  Building wheel for thunder-registration (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for thunder-registration: filename=thunder_registration-1.0.1-py2.py3-none-any.whl size=5343 sha256=8c9daec3f517ced0073b57a0605dcde24aa23d937e16d2c3f26344b82a3592fa\n",
            "  Stored in directory: /root/.cache/pip/wheels/07/48/ce/71fd2426d1bff16e69c41f8e98bdd08b95a3986369582612ba\n",
            "  Building wheel for thunder-python (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for thunder-python: filename=thunder_python-1.4.2-py3-none-any.whl size=43290 sha256=e645d89573c64055a7c9d3f8a85171c41df38a648e6ae705dd8cbd51d3de813a\n",
            "  Stored in directory: /root/.cache/pip/wheels/ba/43/af/c422f29151876dca3c6be2ce49bac784330dd4df4eab82ca12\n",
            "  Building wheel for bolt-python (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bolt-python: filename=bolt_python-0.7.1-py3-none-any.whl size=31181 sha256=4563a97cda248bbb413ddf4dd15dbdbab0879d3486979c051bcba6a5f53b6965\n",
            "  Stored in directory: /root/.cache/pip/wheels/3a/f7/15/0a7c49cb027f8e0805dc0f1d9c25bff3e0b88de009f0048aa5\n",
            "  Building wheel for utm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for utm: filename=utm-0.7.0-py3-none-any.whl size=6107 sha256=ebff907ec493e1de68f1aed12bdc8fcf4547cbf0ac44e28cab46b3d8e12d63b3\n",
            "  Stored in directory: /root/.cache/pip/wheels/a5/b0/12/7ee4fdb0f9fbb4157100bd02390436ed5d58ebfd3c6d6a0886\n",
            "Successfully built sentinelhub stringcase thunder-registration thunder-python bolt-python utm\n",
            "Installing collected packages: urllib3, jmespath, mypy-extensions, marshmallow, botocore, typing-inspect, stringcase, s3transfer, munch, marshmallow-enum, utm, pyproj, fs, fiona, dataclasses-json, boto3, boto, bolt-python, aenum, thunder-python, sentinelhub, geopandas, fs-s3fs, thunder-registration, rtree, rasterio, opencv-contrib-python-headless, eo-learn-core, eo-learn-visualization, eo-learn-ml-tools, eo-learn-mask, eo-learn-io, eo-learn-geometry, eo-learn-features, eo-learn-coregistration, eo-learn\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: rasterio\n",
            "    Found existing installation: rasterio 1.2.6\n",
            "    Uninstalling rasterio-1.2.6:\n",
            "      Successfully uninstalled rasterio-1.2.6\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.25.1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed aenum-3.1.0 bolt-python-0.7.1 boto-2.49.0 boto3-1.18.14 botocore-1.21.14 dataclasses-json-0.5.4 eo-learn-0.9.2 eo-learn-core-0.9.2 eo-learn-coregistration-0.9.0 eo-learn-features-0.9.2 eo-learn-geometry-0.9.2 eo-learn-io-0.9.2 eo-learn-mask-0.9.0 eo-learn-ml-tools-0.9.0 eo-learn-visualization-0.9.0 fiona-1.8.20 fs-2.4.13 fs-s3fs-1.1.1 geopandas-0.9.0 jmespath-0.10.0 marshmallow-3.13.0 marshmallow-enum-1.5.1 munch-2.5.0 mypy-extensions-0.4.3 opencv-contrib-python-headless-4.5.3.56 pyproj-3.1.0 rasterio-1.1.8 rtree-0.9.7 s3transfer-0.5.0 sentinelhub-3.3.2 stringcase-1.2.0 thunder-python-1.4.2 thunder-registration-1.0.1 typing-inspect-0.7.1 urllib3-1.26.6 utm-0.7.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7pebj4k8wf3K",
        "outputId": "36265914-0c4e-497a-fa7e-04bf4e1ae58b"
      },
      "source": [
        "# Built-in modules\n",
        "import sys\n",
        "import os\n",
        "import shutil\n",
        "import datetime\n",
        "import copy\n",
        "import json\n",
        "from pathlib import Path\n",
        "from radiant_mlhub import Collection\n",
        "from radiant_mlhub.client import _download as download_file\n",
        "import tarfile\n",
        "import glob\n",
        "from typing import Tuple\n",
        "import time\n",
        "\n",
        "\n",
        "# Machine learning\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import lightgbm as lgb\n",
        "import joblib\n",
        "from sklearn import preprocessing, metrics\n",
        "from sklearn.metrics import log_loss\n",
        "\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "# Basics of Python data handling and visualization\n",
        "import rasterio\n",
        "import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Imports from eo-learn and sentinelhub-py\n",
        "from eolearn.core import EOPatch, EOTask, FeatureType, LoadTask,MergeFeatureTask,MapFeatureTask, ZipFeatureTask, OverwritePermission\n",
        "from eolearn.mask import AddValidDataMaskTask\n",
        "from eolearn.features import NormalizedDifferenceIndexTask, LinearInterpolation, SimpleFilterTask, ValueFilloutTask\n",
        "from eolearn.geometry import PointSamplingTask, ErosionTask\n",
        "\n",
        "# Pytorch tensors\n",
        "# Modelling - pytorch\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms.functional as TF\n",
        "import torchvision.transforms as T\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import models, transforms\n",
        "# Split the data into two groups:\n",
        "from sklearn.model_selection import ShuffleSplit\n",
        "# Create train_ds and val_ds\n",
        "from torch.utils.data import Subset"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/yaml/constructor.py:126: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
            "  if not isinstance(key, collections.Hashable):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9vER30SwnaM"
      },
      "source": [
        "# DOWNLOAD_S1 = False # If you set this to true then the Sentinel-1 data will be downloaded\n",
        "\n",
        "# # Select which imagery bands you'd like to download here\n",
        "# DOWNLOAD_BANDS = {\n",
        "#     'B01': True,\n",
        "#     'B02': True,\n",
        "#     'B03': True,\n",
        "#     'B04': True,\n",
        "#     'B05': True,\n",
        "#     'B06': True,\n",
        "#     'B07': True,\n",
        "#     'B08': True,\n",
        "#     'B8A': True,\n",
        "#     'B09': True,\n",
        "#     'B11': True,\n",
        "#     'B12': True,\n",
        "#     'CLM': True\n",
        "# }"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qe20LyNSwndh"
      },
      "source": [
        "# FOLDER_BASE = 'ref_south_africa_crops_competition_v1'\n",
        "# os.environ['MLHUB_API_KEY'] = 'ac55f7d60f86044b9d6229b038f1352e75026b57cec007a23cbc9f3a702716b5'\n",
        "\n",
        "# def download_archive(archive_name):\n",
        "#     if os.path.exists(archive_name.replace('.tar.gz', '')):\n",
        "#         return\n",
        "    \n",
        "#     print(f'Downloading {archive_name} ...')\n",
        "#     download_url = f'https://radiant-mlhub.s3.us-west-2.amazonaws.com/archives/{archive_name}'\n",
        "#     download_file(download_url, '.')\n",
        "#     print(f'Extracting {archive_name} ...')\n",
        "#     with tarfile.open(archive_name) as tfile:\n",
        "#         tfile.extractall()\n",
        "#     os.remove(archive_name)\n",
        "\n",
        "# for split in ['train','test']:\n",
        "#     # Download the labels\n",
        "#     labels_archive = f'{FOLDER_BASE}_{split}_labels.tar.gz'\n",
        "#     download_archive(labels_archive)\n",
        "    \n",
        "#     # Download Sentinel-1 data\n",
        "#     if DOWNLOAD_S1:\n",
        "#         s1_archive = f'{FOLDER_BASE}_{split}_source_s1.tar.gz'\n",
        "#         download_archive(s1_archive)\n",
        "        \n",
        "\n",
        "#     for band, download in DOWNLOAD_BANDS.items():\n",
        "#         if not download:\n",
        "#             continue\n",
        "#         s2_archive = f'{FOLDER_BASE}_{split}_source_s2_{band}.tar.gz'\n",
        "#         download_archive(s2_archive)\n",
        "        \n",
        "# def resolve_path(base, path):\n",
        "#     return Path(os.path.join(base, path)).resolve()\n",
        "        \n",
        "# def load_df(collection_id):\n",
        "#     split = collection_id.split('_')[-2]\n",
        "#     collection = json.load(open(f'{collection_id}/collection.json', 'r'))\n",
        "#     rows = []\n",
        "#     item_links = []\n",
        "#     for link in collection['links']:\n",
        "#         if link['rel'] != 'item':\n",
        "#             continue\n",
        "#         item_links.append(link['href'])\n",
        "        \n",
        "#     for item_link in item_links:\n",
        "#         item_path = f'{collection_id}/{item_link}'\n",
        "#         current_path = os.path.dirname(item_path)\n",
        "#         item = json.load(open(item_path, 'r'))\n",
        "#         tile_id = item['id'].split('_')[-1]\n",
        "#         for asset_key, asset in item['assets'].items():\n",
        "#             rows.append([\n",
        "#                 tile_id,\n",
        "#                 None,\n",
        "#                 None,\n",
        "#                 asset_key,\n",
        "#                 str(resolve_path(current_path, asset['href']))\n",
        "#             ])\n",
        "            \n",
        "#         for link in item['links']:\n",
        "#             if link['rel'] != 'source':\n",
        "#                 continue\n",
        "#             source_item_id = link['href'].split('/')[-2]\n",
        "            \n",
        "#             if source_item_id.find('_s1_') > 0 and not DOWNLOAD_S1:\n",
        "#                 continue\n",
        "#             elif source_item_id.find('_s1_') > 0:\n",
        "#                 for band in ['VV', 'VH']:\n",
        "#                     asset_path = Path(f'{FOLDER_BASE}_{split}_source_s1/{source_item_id}/{band}.tif').resolve()\n",
        "#                     date = '-'.join(source_item_id.split('_')[10:13])\n",
        "                    \n",
        "#                     rows.append([\n",
        "#                         tile_id,\n",
        "#                         f'{date}T00:00:00Z',\n",
        "#                         's1',\n",
        "#                         band,\n",
        "#                         asset_path\n",
        "#                     ])\n",
        "                \n",
        "#             if source_item_id.find('_s2_') > 0:\n",
        "#                 for band, download in DOWNLOAD_BANDS.items():\n",
        "#                     if not download:\n",
        "#                         continue\n",
        "                    \n",
        "#                     asset_path = Path(f'{FOLDER_BASE}_{split}_source_s2_{band}/{source_item_id}_{band}.tif').resolve()\n",
        "#                     date = '-'.join(source_item_id.split('_')[10:13])\n",
        "#                     rows.append([\n",
        "#                         tile_id,\n",
        "#                         f'{date}T00:00:00Z',\n",
        "#                         's2',\n",
        "#                         band,\n",
        "#                         asset_path\n",
        "#                     ])\n",
        "            \n",
        "#     return pd.DataFrame(rows, columns=['tile_id', 'datetime', 'satellite_platform', 'asset', 'file_path'])\n",
        "\n",
        "# train_df = load_df(f'{FOLDER_BASE}_train_labels')\n",
        "# test_df = load_df(f'{FOLDER_BASE}_test_labels')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZzfOAhBGwngm"
      },
      "source": [
        "def load_image(paths):\n",
        "  img = list()\n",
        "  for path in paths:\n",
        "      band = rasterio.open(path)\n",
        "      band_array = band.read(1)\n",
        "      #band_array = np.expand_dims(band.read(1).flatten(), axis=1)\n",
        "      img.append(band_array)\n",
        "  return np.dstack(img)\n",
        "\n",
        "def load_timeseries(band_paths: list):\n",
        "  global idx\n",
        "  tstack = list()\n",
        "  for i in range(0, len(band_paths),13):\n",
        "    band_path = band_paths[idx:idx+13]\n",
        "    tstack.append(load_image(band_path))\n",
        "    idx+=13\n",
        "  return np.stack(tstack)\n",
        "\n",
        "def load_label(labels_path):\n",
        "  raster = rasterio.open(labels_path)\n",
        "  return raster.read(1)\n",
        "\n",
        "def load_field_id(fields_path):\n",
        "  raster = rasterio.open(fields_path)\n",
        "  return raster.read(1)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7hnuiCMwnjx"
      },
      "source": [
        "def get_tiles_path(train_df):\n",
        "  bands = ['B01', 'B02', 'B03', 'B04', 'B05', 'B06', 'B07','B08', 'B09', 'B11', 'B12', 'B8A', 'CLM']\n",
        "  tile_ids_train = train_df['tile_id'].unique()\n",
        "  tile_paths = {}\n",
        "  for tile_id in tile_ids_train:\n",
        "    tile_df = train_df[train_df['tile_id']==tile_id]\n",
        "    paths = [str(file_path) for file_path in tile_df['file_path']]\n",
        "\n",
        "    bands_paths = [file_path for file_path in paths if any(f in file_path for f in bands) ]\n",
        "    label_path = [file_path for file_path in paths if any(f in file_path for f in ['labels.tif']) ]\n",
        "    filed_id_path = [file_path for file_path in paths if any(f in file_path for f in ['field_ids.tif']) ]\n",
        "    tile_dates = [date for date in tile_df['datetime'] if date is not None ]\n",
        "\n",
        "    tile_paths[tile_id] = []\n",
        "\n",
        "    tile_paths[tile_id].append(bands_paths)\n",
        "    tile_paths[tile_id].append(label_path)\n",
        "    tile_paths[tile_id].append(filed_id_path)\n",
        "    tile_paths[tile_id].append(tile_dates)\n",
        "    \n",
        "  return tile_paths"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfVzKrmawnnY"
      },
      "source": [
        "# Work flow of prepare the eopatch (count valid pixels, extract Indices, ...)\n",
        "\n",
        "band_names = ['B01', 'B02', 'B03', 'B04', 'B05', 'B06', 'B07',\n",
        "         'B08', 'B09', 'B11', 'B12', 'B8A', 'CLM']\n",
        "\n",
        "# 1.0 count valid pixels\n",
        "class AddValidCountTask(EOTask):\n",
        "  def __init__(self, count_what, feature_name):\n",
        "    self.what = count_what\n",
        "    self.name = feature_name\n",
        "\n",
        "  def execute(self, eopatch):\n",
        "    eopatch[(FeatureType.MASK_TIMELESS, self.name)] = np.count_nonzero(eopatch.mask[self.what], axis=0)\n",
        "    return eopatch\n",
        "\n",
        "AddValidCount = AddValidCountTask('Valid_Data', 'Valid_Count')\n",
        "\n",
        "# 2.0 CALCULATING NEW FEATURES (extract Indices)\n",
        "## NDVI: (B08 - B04)/(B08 + B04)\n",
        "## NDWI: (B03 - B08)/(B03 + B08)\n",
        "## NDBI: (B11 - B08)/(B11 + B08)\n",
        "ndvi = NormalizedDifferenceIndexTask((FeatureType.DATA, 'S2-BANDS-L2A'), (FeatureType.DATA, 'NDVI'),\n",
        "                                     [band_names.index('B08'), band_names.index('B04')])\n",
        "ndwi = NormalizedDifferenceIndexTask((FeatureType.DATA, 'S2-BANDS-L2A'), (FeatureType.DATA, 'NDWI'),\n",
        "                                     [band_names.index('B03'), band_names.index('B08')])\n",
        "ndbi = NormalizedDifferenceIndexTask((FeatureType.DATA, 'S2-BANDS-L2A'), (FeatureType.DATA, 'NDBI'),\n",
        "                                     [band_names.index('B11'), band_names.index('B08')])\n",
        "\n",
        "\n",
        "\n",
        "# 3.0 FEATURE CONCATENATION\n",
        "concatenate = MergeFeatureTask({FeatureType.DATA: ['S2-BANDS-L2A', 'NDVI', 'NDWI', 'NDBI']},\n",
        "                               (FeatureType.DATA, 'FEATURES'))\n",
        "\n",
        "\n",
        "# 4.0 Remove frames with valid data less than 80% \n",
        "class ValdDataFractionPredicate:\n",
        "     \n",
        "    ## Predicate that defines if a frame from EOPatch's time-series is valid or not. Frame is valid if the\n",
        "    ## valid data fraction is above the specified threshold.\n",
        "    def __init__(self, threshold):\n",
        "      self.threshold = threshold\n",
        "\n",
        "    def __call__(self, array):\n",
        "      #clouds = np.count_nonzero(eopatch.mask[self.what] == 1, axis=0)\n",
        "      #array = np.logical_not(array.astype(bool))\n",
        "      coverage = np.sum(array.astype(np.uint8)) / np.prod(array.shape)\n",
        "      return coverage > self.threshold\n",
        "\n",
        "## 4.1 Keep frames with > 80% valid data\n",
        "valid_data_predicate = ValdDataFractionPredicate(0.80)\n",
        "filter_task = SimpleFilterTask((FeatureType.MASK, 'Valid_Data'), valid_data_predicate)\n",
        "\n",
        "# 6.0 EROSION\n",
        "## erode each class of the reference map\n",
        "erosion = ErosionTask(mask_feature=(FeatureType.MASK_TIMELESS,'CROP_ID','CROP_ERODED'), disk_radius=1)\n",
        "\n",
        "\n",
        "## Fill missing values\n",
        "fillout = ValueFilloutTask((FeatureType.DATA, 'FEATURES'), 'fb')\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V94Lr1FUxDWq"
      },
      "source": [
        "def save_data(data, field_id, dates, folder, label= None):\n",
        "    \"\"\"\n",
        "    Creates an EOPatch and adds data:    \n",
        "    \"\"\"\n",
        "    if label is None:\n",
        "      # 5.0 LINEAR TEMPORAL INTERPOLATION\n",
        "      ## linear interpolation of full time-series and date resampling\n",
        "      resampled_range = ('2017-04-01', '2017-11-30', 20)\n",
        "      linear_interp = LinearInterpolation(\n",
        "          'FEATURES', # name of field to interpolate\n",
        "          mask_feature=(FeatureType.MASK, 'Valid_Data'), # mask to be used in interpolation\n",
        "          copy_features=[(FeatureType.MASK_TIMELESS, 'FIELD_ID')], # features to keep\n",
        "          resample_range=resampled_range)\n",
        "    else:\n",
        "      # 5.0 LINEAR TEMPORAL INTERPOLATION\n",
        "      ## linear interpolation of full time-series and date resampling\n",
        "      resampled_range = ('2017-04-01', '2017-11-30', 20)\n",
        "      linear_interp = LinearInterpolation(\n",
        "          'FEATURES', # name of field to interpolate\n",
        "          mask_feature=(FeatureType.MASK, 'Valid_Data'), # mask to be used in interpolation\n",
        "          copy_features=[(FeatureType.MASK_TIMELESS, 'CROP_ID'),(FeatureType.MASK_TIMELESS, 'FIELD_ID')], # features to keep\n",
        "          resample_range=resampled_range,)\n",
        "      \n",
        "    eopatch = EOPatch()\n",
        "    \n",
        "    # Add features to the eopatch\n",
        "    eopatch.add_feature(FeatureType.DATA, 'S2-BANDS-L2A', data[..., :12])\n",
        "    eopatch.add_feature(FeatureType.MASK_TIMELESS, 'FIELD_ID', field_id[...,np.newaxis])\n",
        "    eopatch.timestamp = dates\n",
        "\n",
        "    if label is not None:\n",
        "      eopatch.add_feature(FeatureType.MASK_TIMELESS, 'CROP_ID', label[...,np.newaxis])\n",
        "      \n",
        "\n",
        "    # Valid data\n",
        "    cloud_mask = data[..., -1][...,np.newaxis]\n",
        "    cloud_mask = np.where(cloud_mask==255, 0, cloud_mask)\n",
        "    valid_data =  np.logical_not(cloud_mask)\n",
        "    eopatch.add_feature(FeatureType.MASK, 'Valid_Data', valid_data)\n",
        "  \n",
        "\n",
        "    # Extract new features\n",
        "    eopatch = ndvi.execute(eopatch)\n",
        "    eopatch = ndwi.execute(eopatch)\n",
        "    eopatch = ndbi.execute(eopatch)\n",
        "    eopatch = concatenate.execute(eopatch) \n",
        "\n",
        "    # Remove frames with less than 80% of valid data\n",
        "    eopatch = filter_task.execute(eopatch)\n",
        "\n",
        "    # Linear interpolation - resample time series\n",
        "    eopatch = linear_interp.execute(eopatch)\n",
        "    eopatch = fillout.execute(eopatch)\n",
        "\n",
        "    \n",
        "    fields = eopatch.mask_timeless['FIELD_ID']\n",
        "    featuers = eopatch.data['FEATURES']\n",
        "    \n",
        "    if label is not None:\n",
        "      crops = eopatch.mask_timeless['CROP_ID']\n",
        "\n",
        "    for field in np.unique(fields):\n",
        "      if field != 0:\n",
        "        mask = fields == field\n",
        "        masked_field = np.ma.masked_array(fields, ~mask)\n",
        "        if label is not None:\n",
        "          masked_crop = np.ma.masked_array(crops, ~mask)\n",
        "        \n",
        "        true_points = np.argwhere(masked_field)\n",
        "        top_left = true_points.min(axis=0)\n",
        "        bottom_right = true_points.max(axis=0)\n",
        "        cropped_featuers = featuers[:,top_left[0]:bottom_right[0]+1,top_left[1]:bottom_right[1]+1]\n",
        "        cropped_featuers = cropped_featuers.transpose([0,3,1,2]) \n",
        "\n",
        "        if label is not None:\n",
        "          cropped_mask = masked_crop[top_left[0]:bottom_right[0]+1,top_left[1]:bottom_right[1]+1]\n",
        "          crop_id = np.bincount(cropped_mask.data[np.nonzero(cropped_mask.data)]).argmax()\n",
        "          cropped_mask = np.where(cropped_mask.data == crop_id, crop_id, 0)\n",
        "\n",
        "          np_folder = f'{folder}/{crop_id-1}/{field}.npy'\n",
        "          #np.savez(np_folder, features=cropped_featuers, labels=cropped_mask)\n",
        "          \n",
        "          np.save(np_folder, cropped_featuers,allow_pickle=True, fix_imports=True)\n",
        "        \n",
        "        else:\n",
        "          np_folder = f'{folder}/{field}.npy'\n",
        "          np.save(np_folder, cropped_featuers,allow_pickle=True, fix_imports=True)\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xdFPmU_xDZt"
      },
      "source": [
        "## location of exported fields images\n",
        "data_dir = ['./drive/MyDrive/Zindi/train', './drive/MyDrive/Zindi/test']\n",
        "\n",
        "for directory in data_dir:\n",
        "  if not os.path.isdir(directory):\n",
        "      os.makedirs(directory)\n",
        "      if directory == './drive/MyDrive/Zindi/train':\n",
        "        for c in range(9):\n",
        "          os.mkdir(f\"{directory}/{c}\")\n",
        "      \n",
        "def read_data(all_paths, tiles , data_type='train'):\n",
        "  global idx\n",
        "  l =[]\n",
        "  for tile in tqdm.tqdm(tiles):\n",
        "    idx = 0\n",
        "    # Create numpy file\n",
        "    folder = f'./drive/MyDrive/Zindi/{data_type}'\n",
        "\n",
        "    tile_paths = all_paths[tile]\n",
        "\n",
        "    # Extract time series\n",
        "    all_bands_path = tile_paths[0]\n",
        "    timeseries = load_timeseries(all_bands_path)\n",
        "    # Extract fields IDs\n",
        "    fields = load_field_id(tile_paths[2][0])\n",
        "    dates= list(np.unique(tile_paths[3]))\n",
        "\n",
        "    if data_type != 'test':\n",
        "      # Extract the labels (crops IDs)\n",
        "      labels = load_label(tile_paths[1][0])\n",
        "\n",
        "    if data_type != 'test':\n",
        "      eopatch = save_data(timeseries, fields, dates, folder, label= labels)\n",
        "    else:\n",
        "      eopatch = save_data(data, fields, folder, dates)\n",
        "\n",
        "\n",
        "    del timeseries, labels, fields, dates\n",
        "    \n",
        "    ## No need for this anymore - because we have enough storage now :)\n",
        "    #shutil.rmtree(tile_paths[2][0].replace('field_ids.tif',\"\"))\n",
        "    #for pand_path in all_bands_path:\n",
        "    #   os.remove(pand_path)\n",
        "  "
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-EyHbIclxRXo"
      },
      "source": [
        "##Modeling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCbt6aCpxDdE"
      },
      "source": [
        "# Define the CropsDataset class:\n",
        "class CropsDataset(Dataset):\n",
        "  def __init__(self, paths_df, transform=True, data='train'):\n",
        "    self.paths_df = paths_df\n",
        "    self.transform = transform\n",
        "    self.data = data\n",
        "      \n",
        "  def __len__(self):\n",
        "    return self.paths_df.shape[0]\n",
        "\n",
        "  def pad_crop(self, features):\n",
        "    \"\"\"\n",
        "     Padding and croping to size 64*64\n",
        "    \"\"\"\n",
        "    train_arr = torch.zeros((13,15,64,64))\n",
        "    t,c,h,w = features.shape\n",
        "    if h <= 64 and w <= 64:\n",
        "      train_arr[:,:,:h,:w] = features\n",
        "    elif h<=64:\n",
        "      features = features[:,:,:,:64]\n",
        "      train_arr[:,:,:h,:w] = features\n",
        "    elif w<=64:\n",
        "      features = features[:,:,:64,:]\n",
        "      train_arr[:,:,:h,:w] = features  \n",
        "    else:\n",
        "      train_arr = features[:,:,:64,:64]\n",
        "      \n",
        "    return train_arr\n",
        "\n",
        "  def augment(self, img):\n",
        "    p = np.random.random(4)\n",
        "    ## Apply flipping\n",
        "    if p[0] > 0.5:\n",
        "      img = TF.hflip(img)\n",
        "    if p[1] > 0.5:\n",
        "      img = TF.vflip(img)\n",
        "    ## Apply rotation\n",
        "    if p[2] > 0.5:\n",
        "      angle = np.random.randint(-30, 30)\n",
        "      img = TF.rotate(img, angle)\n",
        "\n",
        "    return img\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "  \n",
        "    img_path = self.paths_df['Path'][index]\n",
        "    \n",
        "    features = np.load(img_path, allow_pickle=True) # this if we save the numpy as np\n",
        "\n",
        "    #features= np.load(img_path)['features'] # this if we save the numpy as npz, in case saved with the crop mask (for segmentation)\n",
        "\n",
        "    field = self.paths_df['Field'][index]\n",
        "   \n",
        "    label= 0\n",
        "    if self.data != 'test':\n",
        "      label = self.paths_df['Crop'][index]\n",
        "      label = torch.tensor(label, dtype=torch.long)\n",
        "\n",
        "    features = torch.tensor(features, dtype=torch.float32)\n",
        "    if self.transform:\n",
        "      features = self.augment(features)\n",
        "    \n",
        "    #features = torch.tensor(features, dtype=torch.float32)\n",
        "\n",
        "    return self.pad_crop(features), label , field"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Z3ZZiR5xDhi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "5307c53e-8d7e-4222-a41d-018e189eb13e"
      },
      "source": [
        "Preprocess = True\n",
        "if Preprocess:\n",
        "  paths = glob.glob('./drive/MyDrive/Zindi/train/*/*.npy')\n",
        "  train_paths_df = pd.DataFrame(paths, columns =['Path'])\n",
        "  f = lambda x: int(x[\"Path\"].split(\"/\")[-1][:-4])\n",
        "  c = lambda x: int(x[\"Path\"].split(\"/\")[-2])\n",
        "  train_paths_df[\"Field\"] = train_paths_df.apply(f, axis=1)\n",
        "  train_paths_df[\"Crop\"] = train_paths_df.apply(c, axis=1)\n",
        "  train_paths_df.to_csv('/content/drive/MyDrive/Zindi/train_paths_df.csv', index=False)\n",
        "\n",
        "train_paths_df = pd.read_csv('/content/drive/MyDrive/Zindi/train_paths_df.csv')\n",
        "train_paths_df.head()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Path</th>\n",
              "      <th>Field</th>\n",
              "      <th>Crop</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>./drive/MyDrive/Zindi/train/0/16713.npy</td>\n",
              "      <td>16713</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>./drive/MyDrive/Zindi/train/0/1196.npy</td>\n",
              "      <td>1196</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>./drive/MyDrive/Zindi/train/0/5309.npy</td>\n",
              "      <td>5309</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>./drive/MyDrive/Zindi/train/0/34415.npy</td>\n",
              "      <td>34415</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>./drive/MyDrive/Zindi/train/0/36486.npy</td>\n",
              "      <td>36486</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                      Path  Field  Crop\n",
              "0  ./drive/MyDrive/Zindi/train/0/16713.npy  16713     0\n",
              "1   ./drive/MyDrive/Zindi/train/0/1196.npy   1196     0\n",
              "2   ./drive/MyDrive/Zindi/train/0/5309.npy   5309     0\n",
              "3  ./drive/MyDrive/Zindi/train/0/34415.npy  34415     0\n",
              "4  ./drive/MyDrive/Zindi/train/0/36486.npy  36486     0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYH7_X4hxfaZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        },
        "outputId": "c2b76c04-3115-4fe7-a402-bc2f43cb145b"
      },
      "source": [
        "# Count the crops\n",
        "train_paths_df['Crop'].value_counts().plot.bar()\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAD1CAYAAACyaJl6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAATYElEQVR4nO3cf5DddX3v8ecLUqxoJUG2FJLQzVyjbbRWcSekQ6djjRMCOIa5YxXaKbmUmj8ar/a2cyXonclcLTM47ZTKtMXJmGhwLBG5dkgvWEzRXqf3yo9FkJ8iW34lKT+2BrAVqwbf94/ziR42u9nsnpM9i3k+Zs6c7/f9+Xy/530Iu6/9/jgnVYUk6eh2zKAbkCQNnmEgSTIMJEmGgSQJw0CShGEgSQIWDLqB2TrppJNqeHh40G1I0kvKHXfc8a9VNTSx/pINg+HhYUZHRwfdhiS9pCR5bLK6p4kkSdOHQZJtSZ5Ocu8kY3+cpJKc1NaT5MokY0nuTnJ619z1SR5qj/Vd9bckuadtc2WS9OvNSZIOz+EcGXwaWDuxmGQpsAZ4vKt8NrC8PTYAV7W5JwKbgTOAlcDmJIvaNlcB7+3a7qDXkiQdWdOGQVV9Fdg3ydAVwAeB7i83WgdcXR23AAuTnAKcBeyqqn1V9QywC1jbxl5VVbdU50uSrgbO6+0tSZJmalbXDJKsA/ZW1TcmDC0Gdnet72m1Q9X3TFKXJM2hGd9NlOR44EN0ThHNqSQb6Jx+4rTTTpvrl5ekn1qzOTL4T8Ay4BtJHgWWAF9P8gvAXmBp19wlrXao+pJJ6pOqqi1VNVJVI0NDB90mK0mapRmHQVXdU1U/X1XDVTVM59TO6VX1JLATuLDdVbQKeK6qngBuAtYkWdQuHK8Bbmpj30myqt1FdCFwfZ/emyTpME17mijJNcBbgZOS7AE2V9XWKabfCJwDjAHPAxcBVNW+JB8Fbm/zPlJVBy5K/wGdO5ZeDnyxPfpmeNMN/dwdAI9efm7f9ylJgzRtGFTVBdOMD3ctF7BxinnbgG2T1EeBN0zXhyTpyPETyJIkw0CSZBhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQOIwySbEvydJJ7u2p/muSbSe5O8rdJFnaNXZpkLMmDSc7qqq9ttbEkm7rqy5Lc2uqfS3JcP9+gJGl6h3Nk8Glg7YTaLuANVfVG4FvApQBJVgDnA69v2/x1kmOTHAv8FXA2sAK4oM0F+BhwRVW9BngGuLindyRJmrFpw6Cqvgrsm1D7UlXtb6u3AEva8jpgR1V9v6oeAcaAle0xVlUPV9UPgB3AuiQB3gZc17bfDpzX43uSJM1QP64Z/B7wxba8GNjdNban1aaqvxp4titYDtQlSXOopzBI8mFgP/DZ/rQz7ettSDKaZHR8fHwuXlKSjgqzDoMk/wV4B/A7VVWtvBdY2jVtSatNVf82sDDJggn1SVXVlqoaqaqRoaGh2bYuSZpgVmGQZC3wQeCdVfV819BO4PwkL0uyDFgO3AbcDixvdw4dR+ci884WIl8B3tW2Xw9cP7u3IkmarcO5tfQa4GvA65LsSXIx8JfAzwG7ktyV5BMAVXUfcC1wP/D3wMaqeqFdE3gfcBPwAHBtmwtwCfBHScboXEPY2td3KEma1oLpJlTVBZOUp/yFXVWXAZdNUr8RuHGS+sN07jaSJA2In0CWJBkGkiTDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRxGN9aqrkxvOmGvu/z0cvP7fs+Jf108shAkmQYSJIMA0kShoEkCcNAkoRhIEnCMJAkcRhhkGRbkqeT3NtVOzHJriQPtedFrZ4kVyYZS3J3ktO7tlnf5j+UZH1X/S1J7mnbXJkk/X6TkqRDO5wjg08DayfUNgE3V9Vy4Oa2DnA2sLw9NgBXQSc8gM3AGcBKYPOBAGlz3tu13cTXkiQdYdOGQVV9Fdg3obwO2N6WtwPnddWvro5bgIVJTgHOAnZV1b6qegbYBaxtY6+qqluqqoCru/YlSZojs71mcHJVPdGWnwRObsuLgd1d8/a02qHqeyapS5LmUM8XkNtf9NWHXqaVZEOS0SSj4+Pjc/GSknRUmG0YPNVO8dCen271vcDSrnlLWu1Q9SWT1CdVVVuqaqSqRoaGhmbZuiRpotmGwU7gwB1B64Hru+oXtruKVgHPtdNJNwFrkixqF47XADe1se8kWdXuIrqwa1+SpDky7VdYJ7kGeCtwUpI9dO4Kuhy4NsnFwGPAu9v0G4FzgDHgeeAigKral+SjwO1t3keq6sBF6T+gc8fSy4EvtockaQ5NGwZVdcEUQ6snmVvAxin2sw3YNkl9FHjDdH1Iko4cP4EsSTIMJEmGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJIELBh0A3ppGd50Q9/3+ejl5/Z9n5JmpqcjgyT/Lcl9Se5Nck2Sn02yLMmtScaSfC7JcW3uy9r6WBsf7trPpa3+YJKzentLkqSZmvWRQZLFwPuBFVX1vSTXAucD5wBXVNWOJJ8ALgauas/PVNVrkpwPfAx4T5IVbbvXA6cC/5DktVX1Qk/vTEc1j2Ckmen1msEC4OVJFgDHA08AbwOua+PbgfPa8rq2ThtfnSStvqOqvl9VjwBjwMoe+5IkzcCsw6Cq9gJ/BjxOJwSeA+4Anq2q/W3aHmBxW14M7G7b7m/zX91dn2QbSdIc6OU00SI6f9UvA54FPg+s7VNfU73mBmADwGmnnXYkX0qaE/0+neWpLM1WL6eJ3g48UlXjVfVD4AvAmcDCdtoIYAmwty3vBZYCtPETgG931yfZ5kWqaktVjVTVyNDQUA+tS5K69XJr6ePAqiTHA98DVgOjwFeAdwE7gPXA9W3+zrb+tTb+5aqqJDuBv0ny53QuIC8HbuuhL0l95MX4o8Osw6Cqbk1yHfB1YD9wJ7AFuAHYkeRPWm1r22Qr8JkkY8A+OncQUVX3tTuR7m/72eidRJI0t3r60FlVbQY2Tyg/zCR3A1XVfwC/NcV+LgMu66UXSdLs+XUUkiTDQJJkGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRI9hkGShUmuS/LNJA8k+bUkJybZleSh9ryozU2SK5OMJbk7yeld+1nf5j+UZH2vb0qSNDO9Hhl8HPj7qvol4FeBB4BNwM1VtRy4ua0DnA0sb48NwFUASU4ENgNnACuBzQcCRJI0N2YdBklOAH4D2ApQVT+oqmeBdcD2Nm07cF5bXgdcXR23AAuTnAKcBeyqqn1V9QywC1g7274kSTPXy5HBMmAc+FSSO5N8MskrgJOr6ok250ng5La8GNjdtf2eVpuqfpAkG5KMJhkdHx/voXVJUrdewmABcDpwVVW9GfguPzklBEBVFVA9vMaLVNWWqhqpqpGhoaF+7VaSjnq9hMEeYE9V3drWr6MTDk+10z+056fb+F5gadf2S1ptqrokaY7MOgyq6klgd5LXtdJq4H5gJ3DgjqD1wPVteSdwYburaBXwXDuddBOwJsmiduF4TatJkubIgh63/6/AZ5McBzwMXEQnYK5NcjHwGPDuNvdG4BxgDHi+zaWq9iX5KHB7m/eRqtrXY1+SpBnoKQyq6i5gZJKh1ZPMLWDjFPvZBmzrpRdJ0uz5CWRJkmEgSTIMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kSfQiDJMcmuTPJ/27ry5LcmmQsyeeSHNfqL2vrY218uGsfl7b6g0nO6rUnSdLMLOjDPj4APAC8qq1/DLiiqnYk+QRwMXBVe36mql6T5Pw27z1JVgDnA68HTgX+Iclrq+qFPvQm6SgxvOmGvu/z0cvP7fs+56uejgySLAHOBT7Z1gO8DbiuTdkOnNeW17V12vjqNn8dsKOqvl9VjwBjwMpe+pIkzUyvp4n+Avgg8KO2/mrg2ara39b3AIvb8mJgN0Abf67N/3F9km1eJMmGJKNJRsfHx3tsXZJ0wKzDIMk7gKer6o4+9nNIVbWlqkaqamRoaGiuXlaSfur1cs3gTOCdSc4BfpbONYOPAwuTLGh//S8B9rb5e4GlwJ4kC4ATgG931Q/o3kaSNAdmfWRQVZdW1ZKqGqZzAfjLVfU7wFeAd7Vp64Hr2/LOtk4b/3JVVauf3+42WgYsB26bbV+SpJnrx91EE10C7EjyJ8CdwNZW3wp8JskYsI9OgFBV9yW5Frgf2A9s9E4iSZpbfQmDqvpH4B/b8sNMcjdQVf0H8FtTbH8ZcFk/epEkzZyfQJYkGQaSJMNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCTRQxgkWZrkK0nuT3Jfkg+0+olJdiV5qD0vavUkuTLJWJK7k5zeta/1bf5DSdb3/rYkSTPRy5HBfuCPq2oFsArYmGQFsAm4uaqWAze3dYCzgeXtsQG4CjrhAWwGzgBWApsPBIgkaW7MOgyq6omq+npb/jfgAWAxsA7Y3qZtB85ry+uAq6vjFmBhklOAs4BdVbWvqp4BdgFrZ9uXJGnm+nLNIMkw8GbgVuDkqnqiDT0JnNyWFwO7uzbb02pT1Sd7nQ1JRpOMjo+P96N1SRJ9CIMkrwT+F/CHVfWd7rGqKqB6fY2u/W2pqpGqGhkaGurXbiXpqNdTGCT5GTpB8Nmq+kIrP9VO/9Cen271vcDSrs2XtNpUdUnSHOnlbqIAW4EHqurPu4Z2AgfuCFoPXN9Vv7DdVbQKeK6dTroJWJNkUbtwvKbVJElzZEEP254J/C5wT5K7Wu1DwOXAtUkuBh4D3t3GbgTOAcaA54GLAKpqX5KPAre3eR+pqn099CVJmqFZh0FV/ROQKYZXTzK/gI1T7GsbsG22vUiSeuMnkCVJhoEkqbdrBpKkGRredEPf9/no5ef2vA+PDCRJhoEkyTCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEliHoVBkrVJHkwylmTToPuRpKPJvAiDJMcCfwWcDawALkiyYrBdSdLRY16EAbASGKuqh6vqB8AOYN2Ae5Kko0aqatA9kORdwNqq+v22/rvAGVX1vgnzNgAb2urrgAf73MpJwL/2eZ/99lLoEeyz3+yzv47mPn+xqoYmFhf0+UWOqKraAmw5UvtPMlpVI0dq//3wUugR7LPf7LO/7PNg8+U00V5gadf6klaTJM2B+RIGtwPLkyxLchxwPrBzwD1J0lFjXpwmqqr9Sd4H3AQcC2yrqvsG0MoROwXVRy+FHsE++80++8s+J5gXF5AlSYM1X04TSZIGyDCQJBkGkiTDYF5LckaSV7Xllyf5n0n+LsnHkpww6P66JfmlJJckubI9Lknyy4Pu61CS/HqSP0qyZtC9HEqSqwfdw1Tav/vqJK+cUF87qJ66JTkuyYVJ3t7WfzvJXybZmORnBt3fAUnen2Tp9DOPYA9eQD5Ykouq6lPzoI/7gF9td1ttAZ4HrgNWt/p/HmiDTZJLgAvofI3InlZeQucW4R1VdfmgeuuW5LaqWtmW3wtsBP4WWAP83XzoM8nEW6oD/CbwZYCqeuecNzWFJO+n89/wAeBNwAeq6vo29vWqOn2Q/bU+PkvnrsnjgWeBVwJfoPMzlKpaP8D2fizJc8B3gX8GrgE+X1Xjc9qDYXCwJI9X1WnzoI8HquqX2/KLfriS3FVVbxpcdz+R5FvA66vqhxPqxwH3VdXywXT2YknurKo3t+XbgXOqajzJK4BbqupXBtth598ZuB/4JFB0wuAaOsFKVf2fwXX3YknuAX6tqv49yTCdP1Q+U1Uf7/5vPUhJ7q6qNyZZQOeDrKdW1QtJAnyjqt444BaBzv+bwFuAtwPvAd4J3EHn3/4LVfVvR7qHefE5g0FIcvdUQ8DJc9nLIdzbdZTyjSQjVTWa5LXAD6fbeA79CDgVeGxC/ZQ2Nl8ck2QRndOjOfCXV1V9N8n+wbb2YyPAB4APA/+9qu5K8r35FAJdjqmqfweoqkeTvBW4Lskv0vk5mg+OaX+UvILO0cEJwD7gZcC8OU0EVFX9CPgS8KV2CutsOkfcfwYc9F1C/XbUhgGdX/hnAc9MqAf4f3PfzqR+H/h4kv9B58uqvpZkN7C7jc0XfwjcnOQhOr0BnAa8BnjflFvNvRPo/LUVoJKcUlVPtPPd8+KXV/uFcEWSz7fnp5i/P6dPJXlTVd0F0I4Q3gFsAwZ+lNVsBb5J58OsHwY+n+RhYBWd05rzxYv+/2tH2TuBnUmOn5MGjtbTREm2Ap+qqn+aZOxvquq3B9DWpNpF5GV0finsqaqnBtzSQZIcQ+eryBe30l7g9qp6YXBdHZ72w3ZyVT0y6F4mSnIucGZVfWjQvUyUZAmwv6qenGTszKr6vwNo6yBJTgWoqn9JspDOqZjHq+q2wXb2E0leW1XfGmgPR2sYSJJ+wltLJUmGgSTJMJAkYRhIkjAMJEnA/wciF+75PQcDFAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nh-emHo9xfeN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b8af4b7-d133-48d9-8a04-0cf9d18f9f8d"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_data, test_data = train_test_split(train_paths_df, test_size=0.20, shuffle=True, random_state=1)\n",
        "\n",
        "# Split test dataset into val/test sets - stratify shuffle\n",
        "test_data, val_data =  train_test_split(test_data, test_size=0.50, shuffle=True, random_state=1,stratify=test_data['Crop'])\n",
        "\n",
        "train_data = train_data.reset_index(drop=True)\n",
        "test_data = test_data.reset_index(drop=True)\n",
        "val_data = val_data.reset_index(drop=True)\n",
        "print(train_data.shape)\n",
        "print(test_data.shape)\n",
        "print(val_data.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50244, 3)\n",
            "(6280, 3)\n",
            "(6281, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3I27IsEuxfgt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        },
        "outputId": "5fde0de1-b83e-41b9-d9a3-6bfb70e7c103"
      },
      "source": [
        "# Check imbalance in train dataset\n",
        "train_data.groupby('Crop').count()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Path</th>\n",
              "      <th>Field</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Crop</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6637</td>\n",
              "      <td>6637</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10956</td>\n",
              "      <td>10956</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6352</td>\n",
              "      <td>6352</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6473</td>\n",
              "      <td>6473</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6608</td>\n",
              "      <td>6608</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>8707</td>\n",
              "      <td>8707</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1199</td>\n",
              "      <td>1199</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>3312</td>\n",
              "      <td>3312</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Path  Field\n",
              "Crop              \n",
              "0      6637   6637\n",
              "1     10956  10956\n",
              "2      6352   6352\n",
              "4      6473   6473\n",
              "5      6608   6608\n",
              "6      8707   8707\n",
              "7      1199   1199\n",
              "8      3312   3312"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKT74j3exfk0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "outputId": "c5b4dc9e-85e3-4a6e-c224-3d7b3fb9d1c9"
      },
      "source": [
        "## create weights to use in the loss function\n",
        "class_count = train_data.groupby('Crop').count().reset_index()\n",
        "class_count['weights'] = class_count['Field'].max() / class_count['Field']\n",
        "class_count"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Crop</th>\n",
              "      <th>Path</th>\n",
              "      <th>Field</th>\n",
              "      <th>weights</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>6637</td>\n",
              "      <td>6637</td>\n",
              "      <td>1.650746</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>10956</td>\n",
              "      <td>10956</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>6352</td>\n",
              "      <td>6352</td>\n",
              "      <td>1.724811</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>6473</td>\n",
              "      <td>6473</td>\n",
              "      <td>1.692569</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>6608</td>\n",
              "      <td>6608</td>\n",
              "      <td>1.657990</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>8707</td>\n",
              "      <td>8707</td>\n",
              "      <td>1.258298</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>1199</td>\n",
              "      <td>1199</td>\n",
              "      <td>9.137615</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>3312</td>\n",
              "      <td>3312</td>\n",
              "      <td>3.307971</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Crop   Path  Field   weights\n",
              "0     0   6637   6637  1.650746\n",
              "1     1  10956  10956  1.000000\n",
              "2     2   6352   6352  1.724811\n",
              "3     4   6473   6473  1.692569\n",
              "4     5   6608   6608  1.657990\n",
              "5     6   8707   8707  1.258298\n",
              "6     7   1199   1199  9.137615\n",
              "7     8   3312   3312  3.307971"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1R7uKSTvxrsK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4c71688-83a4-4af1-b50e-6383cf38328a"
      },
      "source": [
        "# Define data loaders\n",
        "datasets = {'train': CropsDataset(train_data, transform=True, data='train'),\n",
        "            'val': CropsDataset(val_data, transform=False, data='val'),\n",
        "            'test': CropsDataset(test_data, transform=False, data='test')     \n",
        "            }\n",
        "\n",
        "\n",
        "# Define data loaders\n",
        "dataloaders = {'train': torch.utils.data.DataLoader(datasets['train'], batch_size=16, shuffle=True, num_workers=4),\n",
        "              'val': torch.utils.data.DataLoader(datasets['val'], batch_size=16, shuffle=True, num_workers=4),\n",
        "               'test': torch.utils.data.DataLoader(datasets['test'], batch_size=16, shuffle= False, num_workers=4)}"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vnlkz_RZxrwb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "307f90de-491a-4c89-adfd-dbc090c8e6a9"
      },
      "source": [
        "for feature1, label1, field1 in datasets['train']:\n",
        "  print(feature1.shape)\n",
        "  print(label1.shape)\n",
        "  break"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([13, 15, 64, 64])\n",
            "torch.Size([])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vjwq0TmuZOZA",
        "outputId": "438c979a-7ad6-44af-adf1-c3ae9bddd579"
      },
      "source": [
        "  print(label1)\n"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-iBaNu-lyuCj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8acb302b-36f7-432b-b1fa-0e1b7c583697"
      },
      "source": [
        "for feature, label,field in dataloaders['train']:\n",
        "  print(feature.shape)\n",
        "  print(label.shape)\n",
        "  break"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([16, 13, 15, 64, 64])\n",
            "torch.Size([16])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vdaLuDuD2M5"
      },
      "source": [
        "X = "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HIdDZHR9xfo5"
      },
      "source": [
        "b = feature1.numpy()\n",
        "b\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1maA-jN4Rqzs"
      },
      "source": [
        "b = b.reshape()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "id": "bxEf2ZmrCcvB",
        "outputId": "90eb4d00-c1f3-4293-fddd-a8efbb211115"
      },
      "source": [
        "\n",
        "df = pd.DataFrame(b)\n",
        "df.head()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-8047abc7563a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    495\u001b[0m                 \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 497\u001b[0;31m                 \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_ndarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m         \u001b[0;31m# For data is list-like, or Iterable (will consume into list)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36minit_ndarray\u001b[0;34m(values, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;31m# by definition an array here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0;31m# the dtypes will be coerced to a single dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m     \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_prep_ndarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m_prep_ndarray\u001b[0;34m(values, copy)\u001b[0m\n\u001b[1;32m    322\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Must pass 2-d input. shape={values.shape}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Must pass 2-d input. shape=(13, 15, 64, 64)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1co89LtxftK"
      },
      "source": [
        "# Define data loaders\n",
        "datasets1 = {'train': CropsDataset(train_data, transform=True, data='train'),\n",
        "            'val': CropsDataset(val_data, transform=False, data='val'),\n",
        "            'test': CropsDataset(test_data, transform=False, data='test')     \n",
        "            }\n",
        "\n",
        "\n",
        "# # Define data loaders\n",
        "# dataloaders = {'train': torch.utils.data.DataLoader(datasets['train'], batch_size=16, shuffle=True, num_workers=4),\n",
        "#               'val': torch.utils.data.DataLoader(datasets['val'], batch_size=16, shuffle=True, num_workers=4),\n",
        "#                'test': torch.utils.data.DataLoader(datasets['test'], batch_size=16, shuffle= False, num_workers=4)}"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rp5ZuI1fPEBB",
        "outputId": "abe92077-cff7-46c0-e5bd-7fcbdd4a3310"
      },
      "source": [
        "  print(feature2.shape)\n",
        "  print(label2.shape)\n",
        "  break"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([13, 15, 64, 64])\n",
            "torch.Size([])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-lViInZUl8e"
      },
      "source": [
        "StratifiedKFold, Standard Scaler,  Stacked classifier, MLP classifier, voting classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rb5MjBkpPTbL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}